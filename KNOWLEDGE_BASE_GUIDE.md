# Knowledge Base Integration Guide

## ğŸ¯ **What We Built**

A system that scrapes astrology sites daily and stores them in a searchable vector database, then uses semantic search to enrich karma reflections with real-time insights.

---

## âœ… **AWS Setup Complete**

**Knowledge Base ID:** `ZDDIIWWBMV`  
**S3 Bucket:** `karmona-astrology-data-967392725523`  
**Region:** `us-east-2`  
**Status:** Available âœ…

---

## ğŸ“¦ **What's Implemented**

### **1. Browser Scraper** (`app/services/browser_scraper.py`)
- Connects to AWS Bedrock AgentCore browser sandbox
- Uses Playwright to navigate real websites
- Uses Claude to extract specific data
- **Working!** âœ… Tested with NY Post

### **2. Custom Browser Session** (`app/services/karmona_browser_session.py`)
- Handles explicit AWS credentials (works with Coinbase creds in your shell)
- Generates SigV4 signed WebSocket headers
- Creates/manages browser sessions

### **3. Daily Scraper** (`app/services/daily_scraper.py`)
- Scrapes multiple astrology sites:
  - NY Post Astrology (cosmic headlines)
  - Cafe Astrology (aspects, moon phase)
  - Tiny Buddha (spiritual wisdom)
- Uploads formatted documents to S3
- Triggers Knowledge Base sync

### **4. Retrieval Service** (`app/services/kb_retrieval_service.py`)
- Builds smart search queries based on user profile
- Searches Knowledge Base semantically
- Returns top 5 relevant chunks
- Formats context for Claude

### **5. Data Fetchers** (`app/services/data_fetchers/`)
- Higher-level wrappers (can be used or replaced by KB retrieval)

---

## ğŸš€ **How to Use**

### **Run Daily Scraping Job**

```bash
cd /Users/georgiosvasilakis/src/karmona-backend
uv run python scripts/run_daily_scrape.py
```

**This will:**
1. Scrape NY Post, Cafe Astrology, Tiny Buddha
2. Extract astrology insights with Claude
3. Upload to S3 as JSON documents
4. Trigger KB sync (takes ~2-3 minutes)

**Run this:** Once per day (manual for now, automate later)

---

### **Search the Knowledge Base**

```python
from app.services.kb_retrieval_service import KBRetrievalService

retrieval = KBRetrievalService()

context = await retrieval.retrieve_context(
    sun_sign="Capricorn",
    moon_sign="Virgo",
    mood="good",
    actions=["helped", "meditated"],
    zodiac_element="Earth",
    max_results=5,
)

print(context)
# Returns enriched astrology insights relevant to this user!
```

---

## ğŸ”Œ **Next: Wire Into Reflections**

### **Update Reflection Endpoint:**

In `app/routers/reflection.py`:

```python
from app.services.kb_retrieval_service import KBRetrievalService

# ... in generate_reflection() ...

# NEW: Get enriched context from Knowledge Base
retrieval_service = KBRetrievalService()
enriched_context = await retrieval_service.retrieve_context(
    sun_sign=user.sun_sign,
    moon_sign=user.moon_sign,
    mood=request.mood,
    actions=request.actions,
    zodiac_element=astrology_service.get_zodiac_element(user.sun_sign),
)

# Pass to Bedrock service
bedrock_reflection = await bedrock_service.generate_reflection(
    name=user.name,
    sun_sign=user.sun_sign,
    moon_sign=user.moon_sign,
    mood=request.mood,
    actions=request.actions,
    note=request.note,
    horoscope=horoscope,
    enriched_context=enriched_context,  # NEW! Real-time scraped data
    today=today,
)
```

### **Update Bedrock Service:**

In `app/services/bedrock_service.py`, add `enriched_context` parameter to:
- `generate_reflection()` method signature
- `_build_user_prompt()` to include it in Claude's prompt

---

## ğŸ—“ï¸ **Automation Options**

### **Option A: Manual (For Now)**
Run scraping script manually each morning:
```bash
uv run python scripts/run_daily_scrape.py
```

### **Option B: Railway Cron**
If Railway supports cron jobs, schedule to run at 3am daily

### **Option C: AWS EventBridge + Lambda**
- Create Lambda function with scraping code
- EventBridge triggers it daily at 3am UTC

### **Option D: Background Thread in FastAPI**
```python
# In app/main.py
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()
scheduler.add_job(run_daily_scrape, 'cron', hour=3)
scheduler.start()
```

---

## ğŸ’° **Cost Estimates**

**Per scrape run (3 sites):**
- Browser sessions: ~$0.05
- Claude extraction: ~$0.05
- S3 storage: negligible
- KB ingestion: ~$0.01
- **Total: ~$0.11 per day = $3.30/month**

**Per reflection (search):**
- KB retrieve: ~$0.001
- Titan embeddings: ~$0.0001
- **Total: ~$0.001 per reflection**

**OpenSearch Serverless (vector store):**
- ~$0.24/hour = ~$175/month
- **OR** First 750 hours free tier = FREE for first month!

---

## ğŸ§ª **Testing Checklist**

- [ ] Run scraping script manually
- [ ] Verify files appear in S3
- [ ] Wait for KB sync to complete
- [ ] Test retrieval service with sample query
- [ ] Wire into reflection endpoint
- [ ] Generate test reflection with enriched data
- [ ] Compare before/after reflection quality

---

## ğŸ¯ **Next Steps**

1. **Test the scraping:** Run `scripts/run_daily_scrape.py`
2. **Verify S3 upload:** Check S3 bucket has files
3. **Wait for KB sync:** ~2-3 minutes
4. **Test retrieval:** Search KB with sample query
5. **Wire into reflections:** Add to reflection endpoint
6. **Deploy to Railway:** Add KB_ID to env vars

---

## ğŸ”‘ **Environment Variables for Railway**

Add these to Railway:
```
BEDROCK_KNOWLEDGE_BASE_ID=ZDDIIWWBMV
S3_ASTROLOGY_BUCKET=karmona-astrology-data-967392725523
```

---

## ğŸ“š **Architecture Summary**

```
Daily at 3am:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Background Job      â”‚
  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
  â”‚ Scrape 3-5 sites    â”‚
  â”‚ Extract with Claude â”‚
  â”‚ Upload to S3        â”‚
  â”‚ Trigger KB sync     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ S3 Bucket           â”‚
  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
  â”‚ daily/2025-10-12/   â”‚
  â”‚   - nypost.json     â”‚
  â”‚   - cafeastro.json  â”‚
  â”‚   - tinybuddha.json â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (auto-synced)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Knowledge Base      â”‚
  â”‚ (OpenSearch Vector) â”‚
  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
  â”‚ Searchable by       â”‚
  â”‚ semantic meaning    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (searched at runtime)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Reflection Endpoint â”‚
  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
  â”‚ Build query         â”‚
  â”‚ Search KB           â”‚
  â”‚ Get top 5 chunks    â”‚
  â”‚ Pass to Claude      â”‚
  â”‚ Generate reflection â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ‰ **Benefits**

âœ… **Fast reflections** (KB search is < 100ms)  
âœ… **Fresh data** (scraped daily, not stale)  
âœ… **Cost effective** (scrape once, use 1000x)  
âœ… **Semantic search** (finds relevant content intelligently)  
âœ… **Scalable** (works for 10 or 10,000 users)  
âœ… **Competitive moat** (impossible to replicate with just prompts)

---

**Ready to test!** ğŸš€

